{
    "name": "root",
    "gauges": {
        "Walking.Policy.Entropy.mean": {
            "value": 1.8374401330947876,
            "min": 1.8374401330947876,
            "max": 4.350246429443359,
            "count": 10
        },
        "Walking.Policy.Entropy.sum": {
            "value": 91835.2578125,
            "min": 91835.2578125,
            "max": 218182.265625,
            "count": 10
        },
        "Walking.Environment.EpisodeLength.mean": {
            "value": 112.04308390022676,
            "min": 85.09769094138544,
            "max": 403.672,
            "count": 10
        },
        "Walking.Environment.EpisodeLength.sum": {
            "value": 49411.0,
            "min": 47910.0,
            "max": 50459.0,
            "count": 10
        },
        "Walking.Step.mean": {
            "value": 499971.0,
            "min": 49945.0,
            "max": 499971.0,
            "count": 10
        },
        "Walking.Step.sum": {
            "value": 499971.0,
            "min": 49945.0,
            "max": 499971.0,
            "count": 10
        },
        "Walking.Policy.ExtrinsicValueEstimate.mean": {
            "value": 16.745763778686523,
            "min": -0.36295515298843384,
            "max": 16.880313873291016,
            "count": 10
        },
        "Walking.Policy.ExtrinsicValueEstimate.sum": {
            "value": 16528.068359375,
            "min": -393.80633544921875,
            "max": 16576.46875,
            "count": 10
        },
        "Walking.Environment.CumulativeReward.mean": {
            "value": 44.02145731530222,
            "min": -0.2044706857146209,
            "max": 45.92292927399278,
            "count": 10
        },
        "Walking.Environment.CumulativeReward.sum": {
            "value": 19413.46267604828,
            "min": -115.11699605733156,
            "max": 19413.46267604828,
            "count": 10
        },
        "Walking.Policy.ExtrinsicReward.mean": {
            "value": 44.02145731530222,
            "min": -0.2044706857146209,
            "max": 45.92292927399278,
            "count": 10
        },
        "Walking.Policy.ExtrinsicReward.sum": {
            "value": 19413.46267604828,
            "min": -115.11699605733156,
            "max": 19413.46267604828,
            "count": 10
        },
        "Walking.Losses.PolicyLoss.mean": {
            "value": 0.022081909553768736,
            "min": 0.022081909553768736,
            "max": 0.027025832115517307,
            "count": 10
        },
        "Walking.Losses.PolicyLoss.sum": {
            "value": 0.11040954776884368,
            "min": 0.09212134506863852,
            "max": 0.12545563844808688,
            "count": 10
        },
        "Walking.Losses.ValueLoss.mean": {
            "value": 1.8290587290128073,
            "min": 1.6754759073257446,
            "max": 3.3506855551401777,
            "count": 10
        },
        "Walking.Losses.ValueLoss.sum": {
            "value": 9.145293645064037,
            "min": 6.701903629302978,
            "max": 16.75342777570089,
            "count": 10
        },
        "Walking.Policy.LearningRate.mean": {
            "value": 1.6590934469720004e-05,
            "min": 1.6590934469720004e-05,
            "max": 0.00028459590513470006,
            "count": 10
        },
        "Walking.Policy.LearningRate.sum": {
            "value": 8.295467234860002e-05,
            "min": 8.295467234860002e-05,
            "max": 0.0012842484719171997,
            "count": 10
        },
        "Walking.Policy.Epsilon.mean": {
            "value": 0.10553028000000002,
            "min": 0.10553028000000002,
            "max": 0.1948653,
            "count": 10
        },
        "Walking.Policy.Epsilon.sum": {
            "value": 0.5276514000000001,
            "min": 0.5001762000000001,
            "max": 0.9280828000000001,
            "count": 10
        },
        "Walking.Policy.Beta.mean": {
            "value": 0.00028596097200000016,
            "min": 0.00028596097200000016,
            "max": 0.00474377847,
            "count": 10
        },
        "Walking.Policy.Beta.sum": {
            "value": 0.0014298048600000007,
            "min": 0.0014298048600000007,
            "max": 0.021411331720000003,
            "count": 10
        },
        "Walking.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "Walking.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1769458297",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Miniconda\\envs\\mlagents\\Scripts\\mlagents-learn --run-id=usainBolt",
        "mlagents_version": "1.2.0.dev0",
        "mlagents_envs_version": "1.2.0.dev0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1769459081"
    },
    "total": 784.135798999996,
    "count": 1,
    "self": 0.040958199999295175,
    "children": {
        "run_training.setup": {
            "total": 0.19375599999330007,
            "count": 1,
            "self": 0.19375599999330007
        },
        "TrainerController.start_learning": {
            "total": 783.9010848000034,
            "count": 1,
            "self": 1.2279771028843243,
            "children": {
                "TrainerController._reset_env": {
                    "total": 47.898105899992515,
                    "count": 1,
                    "self": 47.898105899992515
                },
                "TrainerController.advance": {
                    "total": 734.6616545971337,
                    "count": 86239,
                    "self": 1.0470057021157118,
                    "children": {
                        "env_step": {
                            "total": 619.7373660976882,
                            "count": 86239,
                            "self": 261.00377859662694,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 358.0031779027195,
                                    "count": 86239,
                                    "self": 3.1406855029490544,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 354.8624923997704,
                                            "count": 83360,
                                            "self": 354.8624923997704
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.7304095983417938,
                                    "count": 86239,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 741.998409998152,
                                            "count": 86239,
                                            "is_parallel": true,
                                            "self": 548.1715386982396,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.031002900010207668,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0008827000274322927,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.030120199982775375,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.030120199982775375
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 193.79586839990225,
                                                    "count": 86239,
                                                    "is_parallel": true,
                                                    "self": 5.332893000842887,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 7.887988897273317,
                                                            "count": 86239,
                                                            "is_parallel": true,
                                                            "self": 7.887988897273317
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 165.78146130178357,
                                                            "count": 86239,
                                                            "is_parallel": true,
                                                            "self": 165.78146130178357
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 14.793525200002478,
                                                            "count": 86239,
                                                            "is_parallel": true,
                                                            "self": 8.873885197695927,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 5.919640002306551,
                                                                    "count": 172478,
                                                                    "is_parallel": true,
                                                                    "self": 5.919640002306551
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 113.87728279732983,
                            "count": 86239,
                            "self": 1.967436295672087,
                            "children": {
                                "process_trajectory": {
                                    "total": 36.924278301681625,
                                    "count": 86239,
                                    "self": 35.71151410168386,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 1.212764199997764,
                                            "count": 1,
                                            "self": 1.212764199997764
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 74.98556819997611,
                                    "count": 48,
                                    "self": 47.78431040016585,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 27.201257799810264,
                                            "count": 1440,
                                            "self": 27.201257799810264
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.999915396794677e-07,
                    "count": 1,
                    "self": 7.999915396794677e-07
                },
                "TrainerController._save_models": {
                    "total": 0.11334640000131913,
                    "count": 1,
                    "self": 0.007519000006141141,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.10582739999517798,
                            "count": 1,
                            "self": 0.10582739999517798
                        }
                    }
                }
            }
        }
    }
}