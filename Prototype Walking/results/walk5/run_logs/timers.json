{
    "name": "root",
    "gauges": {
        "Walking.Policy.Entropy.mean": {
            "value": 4.199012279510498,
            "min": 4.199012279510498,
            "max": 4.3423027992248535,
            "count": 2
        },
        "Walking.Policy.Entropy.sum": {
            "value": 209992.609375,
            "min": 209992.609375,
            "max": 217875.03125,
            "count": 2
        },
        "Walking.Step.mean": {
            "value": 99998.0,
            "min": 49970.0,
            "max": 99998.0,
            "count": 2
        },
        "Walking.Step.sum": {
            "value": 99998.0,
            "min": 49970.0,
            "max": 99998.0,
            "count": 2
        },
        "Walking.Policy.ExtrinsicValueEstimate.mean": {
            "value": -3.0624210834503174,
            "min": -3.0624210834503174,
            "max": -1.3530077934265137,
            "count": 2
        },
        "Walking.Policy.ExtrinsicValueEstimate.sum": {
            "value": -2483.62353515625,
            "min": -2483.62353515625,
            "max": -1079.7001953125,
            "count": 2
        },
        "Walking.Environment.EpisodeLength.mean": {
            "value": 862.0877192982456,
            "min": 862.0877192982456,
            "max": 1029.5106382978724,
            "count": 2
        },
        "Walking.Environment.EpisodeLength.sum": {
            "value": 49139.0,
            "min": 48387.0,
            "max": 49139.0,
            "count": 2
        },
        "Walking.Environment.CumulativeReward.mean": {
            "value": -45.95223936072567,
            "min": -61.14500738585249,
            "max": -45.95223936072567,
            "count": 2
        },
        "Walking.Environment.CumulativeReward.sum": {
            "value": -2619.277643561363,
            "min": -2873.815347135067,
            "max": -2619.277643561363,
            "count": 2
        },
        "Walking.Policy.ExtrinsicReward.mean": {
            "value": -45.95223936072567,
            "min": -61.14500738585249,
            "max": -45.95223936072567,
            "count": 2
        },
        "Walking.Policy.ExtrinsicReward.sum": {
            "value": -2619.277643561363,
            "min": -2873.815347135067,
            "max": -2619.277643561363,
            "count": 2
        },
        "Walking.Losses.PolicyLoss.mean": {
            "value": 0.021217429415943723,
            "min": 0.021217429415943723,
            "max": 0.022607980761677027,
            "count": 2
        },
        "Walking.Losses.PolicyLoss.sum": {
            "value": 0.10608714707971861,
            "min": 0.09043192304670811,
            "max": 0.10608714707971861,
            "count": 2
        },
        "Walking.Losses.ValueLoss.mean": {
            "value": 0.5341434681415558,
            "min": 0.3873517133295536,
            "max": 0.5341434681415558,
            "count": 2
        },
        "Walking.Losses.ValueLoss.sum": {
            "value": 2.6707173407077787,
            "min": 1.5494068533182144,
            "max": 2.6707173407077787,
            "count": 2
        },
        "Walking.Policy.LearningRate.mean": {
            "value": 0.00025685653438116,
            "min": 0.00025685653438116,
            "max": 0.0002845974051342,
            "count": 2
        },
        "Walking.Policy.LearningRate.sum": {
            "value": 0.0012842826719058,
            "min": 0.0011383896205368,
            "max": 0.0012842826719058,
            "count": 2
        },
        "Walking.Policy.Epsilon.mean": {
            "value": 0.18561884,
            "min": 0.18561884,
            "max": 0.19486579999999998,
            "count": 2
        },
        "Walking.Policy.Epsilon.sum": {
            "value": 0.9280942000000001,
            "min": 0.7794631999999999,
            "max": 0.9280942000000001,
            "count": 2
        },
        "Walking.Policy.Beta.mean": {
            "value": 0.004282380116000001,
            "min": 0.004282380116000001,
            "max": 0.00474380342,
            "count": 2
        },
        "Walking.Policy.Beta.sum": {
            "value": 0.021411900580000004,
            "min": 0.01897521368,
            "max": 0.021411900580000004,
            "count": 2
        },
        "Walking.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "Walking.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1765309776",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Miniconda\\envs\\mlagents\\Scripts\\mlagents-learn --run-id=walk5 --force",
        "mlagents_version": "1.2.0.dev0",
        "mlagents_envs_version": "1.2.0.dev0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1765310091"
    },
    "total": 315.18021979997866,
    "count": 1,
    "self": 0.0074878999730572104,
    "children": {
        "run_training.setup": {
            "total": 0.04199880000669509,
            "count": 1,
            "self": 0.04199880000669509
        },
        "TrainerController.start_learning": {
            "total": 315.1307330999989,
            "count": 1,
            "self": 0.37771059924853034,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.790070399991237,
                    "count": 1,
                    "self": 9.790070399991237
                },
                "TrainerController.advance": {
                    "total": 304.83599220076576,
                    "count": 25684,
                    "self": 0.3301897010242101,
                    "children": {
                        "env_step": {
                            "total": 277.2746568992443,
                            "count": 25684,
                            "self": 162.04269729740918,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 115.00709719938459,
                                    "count": 25684,
                                    "self": 0.9857798026350792,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 114.02131739674951,
                                            "count": 25571,
                                            "self": 114.02131739674951
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.22486240245052613,
                                    "count": 25683,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 243.14642070161062,
                                            "count": 25683,
                                            "is_parallel": true,
                                            "self": 164.27839460235555,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00036700000055134296,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0001970000157598406,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00016999998479150236,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00016999998479150236
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 78.86765909925452,
                                                    "count": 25683,
                                                    "is_parallel": true,
                                                    "self": 1.5394093035720289,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 2.213269799394766,
                                                            "count": 25683,
                                                            "is_parallel": true,
                                                            "self": 2.213269799394766
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 70.4987238983158,
                                                            "count": 25683,
                                                            "is_parallel": true,
                                                            "self": 70.4987238983158
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 4.616256097971927,
                                                            "count": 25683,
                                                            "is_parallel": true,
                                                            "self": 2.7921477000636514,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 1.824108397908276,
                                                                    "count": 51366,
                                                                    "is_parallel": true,
                                                                    "self": 1.824108397908276
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 27.231145600497257,
                            "count": 25683,
                            "self": 0.5715078020875808,
                            "children": {
                                "process_trajectory": {
                                    "total": 8.510963898472255,
                                    "count": 25683,
                                    "self": 8.510963898472255
                                },
                                "_update_policy": {
                                    "total": 18.14867389993742,
                                    "count": 12,
                                    "self": 11.629084099840838,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 6.519589800096583,
                                            "count": 360,
                                            "self": 6.519589800096583
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.12695989999338053,
                    "count": 1,
                    "self": 0.006229699996765703,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.12073019999661483,
                            "count": 1,
                            "self": 0.12073019999661483
                        }
                    }
                }
            }
        }
    }
}